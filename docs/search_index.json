[
["data.html", "Chapter 4 Data Structures 4.1 Vectors 4.2 Matrix", " Chapter 4 Data Structures There are different data types that are commonly used in R among which the most important ones are the following: Numeric (or double): these are used to store real numbers. Examples: -4, 12.4532, 6. Integer: examples: 2L, 12L. Logical (or boolean): examples: TRUE, FALSE. Character: examples: &quot;a&quot;, &quot;Bonjour&quot;. In R there are basically five types of data structures in which elements can be stored. A data structure is said to homogeneous if it only contains elements of the same type (for example it only contains character or only numeric values) and heterogenous if it contains elements of more than one type. The five types of data structrures are commonly summarized in a table similar to the one below (see e.g. Wickham 2014): Table 4.1: Five most common types of data structrures used in R (Wickham 2014). Dimension Homogenous Heterogeneous 1 Vector List 2 Matrix Data Frame n Array Consider a simple data set of the top five male single tennis players presented below: Table 4.2: Five best male single tennis players as ranked by ATP (07-15-2017). Name Date of Birth Born Country ATP Ranking Prize Money Win Percentage Grand Slam Wins Andy Murray 15 May 1987 Glasgow, Scotland Great Britain 1 60,449,649 78.07 9 Rafael Nadal 3 June 1986 Manacor, Spain Spain 2 85,920,132 82.48 15 Stan Wawrinka 28 March 1985 Lausanne, Switzerland Switzerland 3 30,577,981 63.96 5 Novak Djokovic 22 May 1987 Belgrade, Serbia Serbia 4 109,447,408 82.77 12 Roger Federer 8 August 1981 Basel, Switzerland Switzerland 5 104,445,185 81.80 18 Notice that this data set contains a variety of data types; in the next sections we will use these data to illustrate how to work with five common data structures. 4.1 Vectors A vector has three important properties: The Type of objects contained in the vector. The function typeof() returns a description of the type of objects in a vector. The Length of a vector indicates the number of elements in the vector. This information can be obtained using the function length(). Attributes are metadata attached to a vector. The functions attr() and attributes() can be used to store and retrive attributes (more details can be found in Section 4.1.4) c() is a generic function which combines arguments to form a vector. All arguments are coerced to a common type which is the type of the returned value, and all attributes except names are removed. For example, consider the number of grand slams won by the five players considered in the eighth column of Table 4.2: grand_slam_win &lt;- c(9, 15, 5, 12, 18) To display the values stored in grand_slam_win we could simply enter the following in the R console: grand_slam_win ## [1] 9 15 5 12 18 Alternatively, we could have created and displayed the value by using () around the definition of the object itself as follows: (grand_slam_win &lt;- c(9, 15, 5, 12, 18)) ## [1] 9 15 5 12 18 Various forms of “nested concatenation” can be used to defined vectors, for example we could also define grand_slam_win as (grand_slam_win &lt;- c(9, c(15, 5, c(12, c(18))))) ## [1] 9 15 5 12 18 This approach is often used to assemble vectors in various ways. It is also possible to define vector with characters, for example we could define a vector with the player names as follows: (players &lt;- c(&quot;Andy Murray&quot;, &quot;Rafael Nadal&quot;, &quot;Stan Wawrinka&quot;, &quot;Novak Djokovic&quot;, &quot;Roger Federer&quot;)) ## [1] &quot;Andy Murray&quot; &quot;Rafael Nadal&quot; &quot;Stan Wawrinka&quot; &quot;Novak Djokovic&quot; ## [5] &quot;Roger Federer&quot; 4.1.1 Type We can evaluate the kind or type of elements that are stored in a vector using the function typeof(). For example, for the vectors we just created we obtain: typeof(grand_slam_win) ## [1] &quot;double&quot; typeof(players) ## [1] &quot;character&quot; This is a little surprising as all the elements in grand_slam_win are integers and it would therefore seem natural to expect this as an output of the function typeof(). This is because R considers any number as a “double” by default, except when adding the suffix L after an integer. For example: typeof(1) ## [1] &quot;double&quot; typeof(1L) ## [1] &quot;integer&quot; Therefore, we could express grand_slam_win as follows: (grand_slam_win_int &lt;- c(9L, 15L, 5L, 12L, 18L)) ## [1] 9 15 5 12 18 typeof(grand_slam_win_int) ## [1] &quot;integer&quot; In general, the difference between the two is relatively unimportant. 4.1.2 Coercion As indicated earlier, a vector has a homogeneous data structure meaning that it can only contain a single type among all the data types. Therefore, when more than one data type is provided, R coerces the data into a “shared” type. To identify this “shared” type we can use this simple rule: \\[\\begin{equation*} \\text{logical} &lt; \\text{integer} &lt; \\text{numeric} &lt; \\text{character}, \\end{equation*}\\] which simply means that if a vector contains more than one data type, the “shared” type will be that of the “largest” type according to the progression shown above. For example: # Logical + numeric (mix_logic_int &lt;- c(TRUE, 12, 0.5)) ## [1] 1.0 12.0 0.5 typeof(mix_logic_int) ## [1] &quot;double&quot; # Numeric + character (mix_int_char &lt;- c(14.3, &quot;Hi&quot;)) ## [1] &quot;14.3&quot; &quot;Hi&quot; typeof(mix_int_char) ## [1] &quot;character&quot; 4.1.3 Subsetting Naturally, it is possible to “subset” the values of in our vector in many ways. Essentially, there are four main ways of subsetting a vector. Here we’ll only discuss the first three: Positive Index: We can access or subset the \\(i\\)-th element of a vector by simply using grand_slam_win[i] where \\(i\\) is a positive number between 1 and length of the vector. # Accesing the first element grand_slam_win[1] ## [1] 9 # Accesing the third and first value grand_slam_win[c(3, 1)] ## [1] 5 9 # Duplicated indices yield duplicated values grand_slam_win[c(1, 1, 2, 2, 3, 4)] ## [1] 9 9 15 15 5 12 Negative Index: We remove elements in a vector using negative indices: # Removing the second obervation grand_slam_win[-2] ## [1] 9 5 12 18 # Removing the first and fourth obserations grand_slam_win[c(-1, -4)] ## [1] 15 5 18 Logical Indices: Another useful approach is based on logical operators: # Access the first and fourth observations grand_slam_win[c(TRUE, FALSE, FALSE, TRUE, FALSE)] ## [1] 9 12 Note that it is not permitted to “mix” positive and negative indices. For example, grand_slam_win[c(-1, 2)] would produce an error message. 4.1.4 Attributes Let’s suppose that we conducted an experiment under specific conditions, say a date and a place which should be stored as attributes of the object containing the results of this experiment. Indeed, objects can have arbitrary additional attributes that are used to store metadata on the object of interest. For example: attr(grand_slam_win, &quot;date&quot;) &lt;- &quot;07-15-2017&quot; attr(grand_slam_win, &quot;type&quot;) &lt;- &quot;Men, Singles&quot; To display the vector with its attributes grand_slam_win ## [1] 9 15 5 12 18 ## attr(,&quot;date&quot;) ## [1] &quot;07-15-2017&quot; ## attr(,&quot;type&quot;) ## [1] &quot;Men, Singles&quot; To only display the attributes we can use attributes(grand_slam_win) ## $date ## [1] &quot;07-15-2017&quot; ## ## $type ## [1] &quot;Men, Singles&quot; It is also possible to extract a specific attribute attr(grand_slam_win, &quot;date&quot;) ## [1] &quot;07-15-2017&quot; 4.1.5 Adding Labels In some cases, it is useful to augment vector elements with labels. For example, we could define the vector grand_slam_win and associate the name of each corresponding athlete as a labels, i.e. (grand_slam_win &lt;- c(&quot;Andy Murray&quot; = 9, &quot;Rafael Nadal&quot; = 15, &quot;Stan Wawrinka&quot; = 5, &quot;Novak Djokovic&quot; = 12, &quot;Roger Federer&quot; = 18)) ## Andy Murray Rafael Nadal Stan Wawrinka Novak Djokovic Roger Federer ## 9 15 5 12 18 The main advantage of this approach is that the number of grand slams won can now be referred to by the player’s name. For example: grand_slam_win[&quot;Andy Murray&quot;] ## Andy Murray ## 9 grand_slam_win[c(&quot;Andy Murray&quot;,&quot;Roger Federer&quot;)] ## Andy Murray Roger Federer ## 9 18 All labels (athlete names in this case) can be obtained with the function names(), i.e. names(grand_slam_win) ## [1] &quot;Andy Murray&quot; &quot;Rafael Nadal&quot; &quot;Stan Wawrinka&quot; &quot;Novak Djokovic&quot; ## [5] &quot;Roger Federer&quot; 4.1.6 Working with Dates When working with dates it is useful to treat them as actual dates rather than character strings that look like dates (to a human) but don’t otherwise behave like dates. For example, consider a vector of three dates: c(&quot;03-21-2015&quot;, &quot;12-13-2011&quot;, &quot;06-27-2008&quot;). The sort() function returns the elements of a vector in ascending order, but since these dates are actually just character strings that look like dates (to a human), R sorts them in alphanumeric order (for characters) rather than chronological order (for dates): # The `sort()` function sorts elements in a vector in ascending order sort(c(&quot;03-21-2015&quot;, &quot;12-31-2011&quot;, &quot;06-27-2008&quot;, &quot;01-01-2012&quot;)) ## [1] &quot;01-01-2012&quot; &quot;03-21-2015&quot; &quot;06-27-2008&quot; &quot;12-31-2011&quot; Converting the character strings to “yyyy-mm-dd” would solve our sorting problem, but perhaps we also want to calculate the number of days between two events that are several months or years apart. The as.Date() function is one straight-forward method for converting character strings into dates that can be used as such. The typical syntax is of the form: as.Dates(&lt;vector of dates&gt;, format = &lt;your format&gt;) Considering the dates of birth presented in Table 4.2 we can save them in an appropriate format using: (players_dob &lt;- as.Date(c(&quot;15 May 1987&quot;, &quot;3 June 1986&quot;, &quot;28 March 1985&quot;, &quot;22 May 1987&quot;, &quot;8 August 1981&quot;), format = &quot;%d %b %Y&quot;)) ## [1] &quot;1987-05-15&quot; &quot;1986-06-03&quot; &quot;1985-03-28&quot; &quot;1987-05-22&quot; &quot;1981-08-08&quot; Note the syntax of format = &quot;%d %b %Y&quot;. The following table shows common format elements for use with the as.Date() function: Table 4.3: Common date formatting elements for use with as.Date() reproduced from http://www.statmethods.net/. Symbol Meaning Example %d day as a number (0-31) 01-31 %a abbreviated weekday Mon %A unabbreviated weekday Monday %m month (00-12) 00-12 %b abbreviated month Jan %B unabbreviated month January %y 2-digit year 07 %Y 4-digit year 2007 There are many advantages to recommend the as.Date() format (in addition to proper sorting). For example, the subtraction between two dates becomes more meaningful and yields to the difference in days between them. As an example, the number of days between Rafael Nadal’s and Andy Murray’s dates of birth can be obtained as players_dob[1] - players_dob[2] ## Time difference of 346 days In addition, subsetting becomes also more intuitive and to find out the players born after 1 January 1986 we can simply run: players[players_dob &gt; &quot;1986-01-01&quot;] ## [1] &quot;Andy Murray&quot; &quot;Rafael Nadal&quot; &quot;Novak Djokovic&quot; There are many other reason for using this format (or other date formats). A more detailed discussion on this topic can for example be found in Cole Beck’s notes. 4.1.7 Useful Functions with Vectors The reason for extracting or creating vectors often lies in the need to collect information from them. For this purpose, a series of useful functions are available that allow to extract information or arrange the vector elements in a certain manner which can be of interest to the user. Among the most commonly used functions we can find the following ones length() sum() mean() order() and sort() whose name is self-explanatory in most cases. For example we have length(grand_slam_win) ## [1] 5 sum(grand_slam_win) ## [1] 59 mean(grand_slam_win) ## [1] 11.8 To sort the players by number of grand slam wins, we could use the function order() which returns the position of the elements of a vector sorted in an ascending order, order(grand_slam_win) ## [1] 3 1 4 2 5 Therefore, we can sort the players in ascending order of wins as follows players[order(grand_slam_win)] ## [1] &quot;Stan Wawrinka&quot; &quot;Andy Murray&quot; &quot;Novak Djokovic&quot; &quot;Rafael Nadal&quot; ## [5] &quot;Roger Federer&quot; which implies that Roger Federer won most grand slams. Another related function is sort() which simply sorts the elements of a vector in an ascending manner. For example, sort(grand_slam_win) ## Stan Wawrinka Andy Murray Novak Djokovic Rafael Nadal Roger Federer ## 5 9 12 15 18 which is compact version of grand_slam_win[order(grand_slam_win)] ## Stan Wawrinka Andy Murray Novak Djokovic Rafael Nadal Roger Federer ## 5 9 12 15 18 It is also possible to use the functions sort() and order() with characters and dates. For example, to sort the players’ names alphabetically (by first name) we can use: sort(players) ## [1] &quot;Andy Murray&quot; &quot;Novak Djokovic&quot; &quot;Rafael Nadal&quot; &quot;Roger Federer&quot; ## [5] &quot;Stan Wawrinka&quot; Similarly, we can sort players by age (oldest first) players[order(players_dob)] ## [1] &quot;Roger Federer&quot; &quot;Stan Wawrinka&quot; &quot;Rafael Nadal&quot; &quot;Andy Murray&quot; ## [5] &quot;Novak Djokovic&quot; or in an reversed manner (oldest last): players[order(players_dob, decreasing = TRUE)] ## [1] &quot;Novak Djokovic&quot; &quot;Andy Murray&quot; &quot;Rafael Nadal&quot; &quot;Stan Wawrinka&quot; ## [5] &quot;Roger Federer&quot; There are of course many other useful functions that allow to deal with vectors which we will not mention in this section but can be found in a variety of references (see e.g. Wickham 2014). 4.1.8 Creating sequences When using R for statistical programming and data analysis it is very common to create sequences of numbers. Here are three common ways used to create such sequences: from:to: This method is quite intuitive and very compact. For example: 1:3 ## [1] 1 2 3 (x &lt;- 3:1) ## [1] 3 2 1 (y &lt;- -1:-4) ## [1] -1 -2 -3 -4 (z &lt;- 1.3:3) ## [1] 1.3 2.3 seq_len(n): This function provides a simple way to generate a sequence from 1 to an arbitrary number n. In general, 1:n and seq_len(n) are equivalent with the notable exceptions where n = 0 and n &lt; 0. The reason for these exceptions will become clear in Section ??. Let’s see a few examples: n &lt;- 3 1:n ## [1] 1 2 3 seq_len(n) ## [1] 1 2 3 n &lt;- 0 1:n ## [1] 1 0 seq_len(n) ## integer(0) seq(a, b, by/length.out = d): This function can be used to create more “complex” sequences. It can either be used to create a sequence from a to b by increments of d (using the option by) or of a total length of d (using the option length.out). A few examples: (x &lt;- seq(1, 2.8, by = 0.4)) ## [1] 1.0 1.4 1.8 2.2 2.6 (y &lt;- seq(1, 2.8, length.out = 6)) ## [1] 1.00 1.36 1.72 2.08 2.44 2.80 This can be combined with the rep() function to create vectors with repeated values or sequences, for example: rep(c(1,2), times = 3, each = 1) ## [1] 1 2 1 2 1 2 rep(c(1,2), times = 1, each = 3) ## [1] 1 1 1 2 2 2 where the option times allows to specify how many times the object needs to be repeated and each regulates how many times each element in the object is repeated. It is also possible to generates sequences of dates using the function seq(). For example, to generate a sequence of 10 dates between the dates of birth of Andy Murray and Rafael Nadal we can use seq(from = players_dob[1], to = players_dob[2], length.out = 10) ## [1] &quot;1987-05-15&quot; &quot;1987-04-06&quot; &quot;1987-02-27&quot; &quot;1987-01-19&quot; &quot;1986-12-12&quot; ## [6] &quot;1986-11-03&quot; &quot;1986-09-26&quot; &quot;1986-08-18&quot; &quot;1986-07-11&quot; &quot;1986-06-03&quot; Similarly, we can create a sequence between the two dates by increment of one week (backward) seq(players_dob[1], players_dob[2], by = &quot;-1 week&quot;) ## [1] &quot;1987-05-15&quot; &quot;1987-05-08&quot; &quot;1987-05-01&quot; &quot;1987-04-24&quot; &quot;1987-04-17&quot; ## [6] &quot;1987-04-10&quot; &quot;1987-04-03&quot; &quot;1987-03-27&quot; &quot;1987-03-20&quot; &quot;1987-03-13&quot; ## [11] &quot;1987-03-06&quot; &quot;1987-02-27&quot; &quot;1987-02-20&quot; &quot;1987-02-13&quot; &quot;1987-02-06&quot; ## [16] &quot;1987-01-30&quot; &quot;1987-01-23&quot; &quot;1987-01-16&quot; &quot;1987-01-09&quot; &quot;1987-01-02&quot; ## [21] &quot;1986-12-26&quot; &quot;1986-12-19&quot; &quot;1986-12-12&quot; &quot;1986-12-05&quot; &quot;1986-11-28&quot; ## [26] &quot;1986-11-21&quot; &quot;1986-11-14&quot; &quot;1986-11-07&quot; &quot;1986-10-31&quot; &quot;1986-10-24&quot; ## [31] &quot;1986-10-17&quot; &quot;1986-10-10&quot; &quot;1986-10-03&quot; &quot;1986-09-26&quot; &quot;1986-09-19&quot; ## [36] &quot;1986-09-12&quot; &quot;1986-09-05&quot; &quot;1986-08-29&quot; &quot;1986-08-22&quot; &quot;1986-08-15&quot; ## [41] &quot;1986-08-08&quot; &quot;1986-08-01&quot; &quot;1986-07-25&quot; &quot;1986-07-18&quot; &quot;1986-07-11&quot; ## [46] &quot;1986-07-04&quot; &quot;1986-06-27&quot; &quot;1986-06-20&quot; &quot;1986-06-13&quot; &quot;1986-06-06&quot; or by increment of one month (forward) seq(players_dob[2], players_dob[1], by = &quot;1 month&quot;) ## [1] &quot;1986-06-03&quot; &quot;1986-07-03&quot; &quot;1986-08-03&quot; &quot;1986-09-03&quot; &quot;1986-10-03&quot; ## [6] &quot;1986-11-03&quot; &quot;1986-12-03&quot; &quot;1987-01-03&quot; &quot;1987-02-03&quot; &quot;1987-03-03&quot; ## [11] &quot;1987-04-03&quot; &quot;1987-05-03&quot; 4.1.9 Example: Apple Stock Price Suppose that one is interested in analyzing the behavior of Apple’s stock price over the last three months. The first thing that is needed to perform such analysis is to recover (automatically) today’s date. In R, this can be obtained as follows (today &lt;- Sys.Date()) ## [1] &quot;2017-09-07&quot; Once this is done, we can obtain the date which is exactly three months ago by using (three_months_ago &lt;- seq(today, length = 2, by = &quot;-3 months&quot;)[2]) ## [1] &quot;2017-06-07&quot; With this information, we can now download Apple’s stock price and represent these stocks through a candlestick chart which summarizes information on daily opening and closing prices as well as minimum and maximum prices. These charts are often used with the hope of detecting trading patterns over a given period of time. library(quantmod) getSymbols(&quot;AAPL&quot;, from = three_months_ago, to = today) candleChart(AAPL, theme=&#39;white&#39;, type=&#39;candles&#39;) Figure 4.1: Candlestick chart for Apple’s stock price for the last three months. Using the price contained in the object we downloaded (i.e. AAPL), we can compute Apple’s arithmetic returns which are defined as follows \\[\\begin{equation} R_t = \\frac{S_t - S_{t-1}}{S_{t-1}}, \\end{equation}\\] where \\(R_t\\) are the returns at time t and \\(S_t\\) is the stock price. This is implemented in the function ClCl() within the quantmod package. For example, we can create a vector of returns as follows AAPL_returns &lt;- na.omit(ClCl(AAPL)) where na.omit() is used to remove missing values in the stock prices vector since, if we have \\(n+1\\) stock prices, we will only have \\(n\\) returns and therefore the first return cannot be computed. We can now compute the mean and median of the returns over the considered period. mean(AAPL_returns) ## [1] 0.000741442 median(AAPL_returns) ## [1] 0.00270089 However, a statistic that is of particular interest to financial operators is the Excess Kurtosis which, for a random variable that we denote as \\(X\\), can be defined as \\[\\begin{equation} \\text{Kurt} = \\frac{{\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^4\\right]}{\\left({\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^2\\right]\\right)^2} - 3. \\end{equation}\\] The reason for defining this statistic as Excess Kurtosis lies in the fact that the standardized kurtosis is compared to that of a Gaussian distribution (whose kurtosis is equal to 3) which has exponentially decaying tails. Consequently, if the Excess Kurtosis is positive, this implies that the distribution has heavier tails than a Gaussian and therefore has higher probabilities of extreme events occurring. To understand why the Excess Kurtosis is equal to 0 for a Gaussian distribution click on button below: Excess Kurtosis Derivation Assuming \\(X\\) to be Gaussian we have \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\). Then, we define \\(Z\\) as \\(Z \\sim \\mathcal{N}(0,1)\\) and \\(Y\\) as \\(Y = Z^2 \\sim \\chi^2_1\\). Remember that a random variable following a \\(\\chi^2_1\\) distribution has the following properties: \\(\\text{Var}[Y] = 2\\) and \\(\\mathbb{E}[Y] = 1\\). Using these definitions and properties, we obtain: \\[\\begin{equation} \\begin{aligned} \\text{Kurt} &amp;= \\frac{{\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^4\\right]}{\\left({\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^2\\right]\\right)^2} - 3 = \\frac{{\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^4\\right]}{\\left[\\text{Var} \\left(X\\right)\\right]^2} - 3 = \\frac{{\\mathbb{E}}\\left[\\left(X - \\mathbb{E}[X]\\right)^4\\right]}{\\sigma^4} - 3\\\\ &amp;= {\\mathbb{E}}\\left[\\left(\\frac{X - \\mathbb{E}[X]}{\\sigma}\\right)^4\\right] - 3 = \\mathbb{E}\\left[Z^4\\right] - 3 = \\text{Var}[Z^2] + \\mathbb{E}^2\\left[Z^2\\right] - 3\\\\ &amp;= \\text{Var}[Y] + \\mathbb{E}^2\\left[Y\\right] - 3 = 0. \\end{aligned} \\end{equation}\\] This implies that the theoretical value of the excess Kurtosis for a normally distributed random variable is \\(0\\). Given this statistic, it is useful to compute this on the observed data and for this purpose a common estimator of the excess Kurtosis is \\[\\begin{equation} k = \\frac{\\frac{1}{n} \\sum_{t = 1}^{n} \\left(R_t -\\bar{R}\\right)^4}{\\left(\\frac{1}{n} \\sum_{t = 1}^{n} \\left(R_t -\\bar{R}\\right)^2 \\right)^2} - 3, \\end{equation}\\] where \\(\\bar{R}\\) denotes the sample average of the returns, i.e. \\[\\begin{equation} \\bar{R} = \\frac{1}{n} \\sum_{i = 1}^n R_i. \\tag{4.1} \\end{equation}\\] In R, this can simply be done as follows: mu &lt;- mean(AAPL_returns) (k &lt;- mean((AAPL_returns - mu)^4)/(mean((AAPL_returns - mu)^2))^2 - 3) ## [1] 2.644067 Therefore, we observe an estimated Excess Kurtosis of 2.64 which is quite high tends to indicate the returns have a heavier tails than the normal distribution. In Chapter @ref(#control), we will revisit this example and investigate if there is enough evidence to conclude that Apple’s stock has Excess Kurtosis larger than zero. 4.2 Matrix Matrices are another extremely common data structure in R. Compared to vectors, matrices have an additional dimension which, for example, allows to stock multiple equidimensional (same length) vectors within the same object. Below is an example of how to create a matrix containing consecutive numbers in R: (mat &lt;- matrix(1:12, ncol = 4, nrow = 3)) ## [,1] [,2] [,3] [,4] ## [1,] 1 4 7 10 ## [2,] 2 5 8 11 ## [3,] 3 6 9 12 Notice that the first argument to the function is a vector (in this case a vector with increasing elements from 1 to 12) which is then transformed into a matrix with four columns (ncol = 4) and three rows (nrow = 3). By default, the vectors are transformed into matrices by placing the elements by column (i.e. starting from the top of the first column to the bottom and then passing to the following column until all columns are full). If you wish to fill the matrix by row, all you need to do is specify the argument byrow = T. # Compare with the matrix above matrix(1:12, ncol = 4, nrow = 3, byrow = T) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 Usually the length of the vector (i.e. number of elements in the vector) is the result of the multiplication between the number of columns and number of rows. What happens if the vector has fewer elements for the same matrix dimension? What happens if the vector has more elements? It is often the case however that we already have equidimensional vectors available and we wish to stock them into a matrix. In these cases, two useful functions are cbind() - column bind - and rbind() - row bind - where the first function stocks the vectors vertically side-by-side while the second stocks the vectors horizontally one below the other. An example of the former is given below: players &lt;- c(&quot;Andy Murray&quot;, &quot;Rafael Nadal&quot;, &quot;Stan Wawrinka&quot;, &quot;Novak Djokovic&quot;, &quot;Roger Federer&quot;) grand_slam_win &lt;- c(9, 15, 5, 12, 18) win_percentage &lt;- c(78.07, 82.48, 63.96, 82.77, 81.80) (mat &lt;- cbind(grand_slam_win, win_percentage)) ## grand_slam_win win_percentage ## [1,] 9 78.07 ## [2,] 15 82.48 ## [3,] 5 63.96 ## [4,] 12 82.77 ## [5,] 18 81.80 The result in this case is a \\(5 \\times 2\\) matrix (with rbind() it would have been a \\(2 \\times 5\\) matrix). Once the matrix is defined, we can assign names to its rows and columns by using respectively rownames and colnames. Of course, the number of names must correspond to the respective matrix dimensions as shown in the following example where each row corresponds to a specific player (thereby using the players vector) and each column corresponds to a specific statistic of the players. rownames(mat) &lt;- players colnames(mat) &lt;- c(&quot;GS win&quot;, &quot;Win rate&quot;) mat ## GS win Win rate ## Andy Murray 9 78.07 ## Rafael Nadal 15 82.48 ## Stan Wawrinka 5 63.96 ## Novak Djokovic 12 82.77 ## Roger Federer 18 81.80 4.2.1 Subsetting As for vectors, it is possible to subset the elements of a matrix. However, in the case of matrices we’re dealing with two-dimensional data structures and it is therefore necessary to specify the position of the elements of interest in both dimensions. For this purpose, as with vectors, we can use [ ] but, as opposed to vectors, we need to add , within the square brackets where the rows are specified before the comma and the columns after it. (eg. matrix[row, column]) Below are a few examples: # Subset players &quot;Stan Wawrinka&quot; and &quot;Roger Federer&quot; mat[c(&quot;Stan Wawrinka&quot;, &quot;Roger Federer&quot;), ] ## GS win Win rate ## Stan Wawrinka 5 63.96 ## Roger Federer 18 81.80 # Subset row 1 and 3 mat[c(1, 3), ] ## GS win Win rate ## Andy Murray 9 78.07 ## Stan Wawrinka 5 63.96 # Subset column 2 only mat[, 2] ## Andy Murray Rafael Nadal Stan Wawrinka Novak Djokovic Roger Federer ## 78.07 82.48 63.96 82.77 81.80 # Subset column 1 of (row 1, 2, and 3) mat[1:3, 1] ## Andy Murray Rafael Nadal Stan Wawrinka ## 9 15 5 It can be noticed that, when a space is left blank before or after the comma, this means that respectively all the rows or all the columns are considered. 4.2.2 Matrix Operators in R As with vectors, there are some useful functions that can be used with matrices. A first example is the function dim() that allows to determine the dimension of a matrix. For example, consider the following \\(4 \\times 2\\) matrix \\[\\begin{equation*} \\mathbf{A} = \\left[ \\begin{matrix} 1 &amp; 5\\\\ 2 &amp; 6\\\\ 3 &amp; 7\\\\ 4 &amp; 8 \\end{matrix} \\right] \\end{equation*}\\] which can be created in R as follows: (A &lt;- matrix(1:8, 4, 2)) ## [,1] [,2] ## [1,] 1 5 ## [2,] 2 6 ## [3,] 3 7 ## [4,] 4 8 Therefore, we expect dim(A) to return the vector c(4, 2). Indeed, we have dim(A) ## [1] 4 2 Next, we consider the function t() allows transpose a matrix. For example, \\(\\mathbf{A}^T\\) is equal to: \\[\\begin{equation*} \\mathbf{A}^T = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 &amp; 4\\\\ 5 &amp; 6 &amp; 7 &amp; 8 \\end{matrix} \\right], \\end{equation*}\\] which is a \\(2 \\times 4\\) matrix. In R, we achieve this as follows (At &lt;- t(A)) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 dim(At) ## [1] 2 4 Aside from playing with matrix dimensions, matrix algebraic operations have specific commands. For example, the operator %*% is used in R to denote matrix multiplication while, as opposed to scalar objects, the regular product operator * performs the Hadamard product (or element by element product) when applied to matrices. For example, consider the following matrix product \\[\\begin{equation*} \\mathbf{B} = \\mathbf{A}^T \\mathbf{A} = \\left[ \\begin{matrix} 30 &amp; 70\\\\ 70 &amp; 174 \\end{matrix} \\right], \\end{equation*}\\] which can be done in R as follows: (B &lt;- At %*% A) ## [,1] [,2] ## [1,] 30 70 ## [2,] 70 174 Other common matrix operations include finding the determinant of a matrix and finding its inverse. These are often used, for example, when computing the likelihood function for a variable following a Gaussian distribution or when simulating time series or spatial data. The functions that perform these operations are det() and solve() that respectively find the determinant and the inverse of a matrix (which necessarily has to be square). The function det() can be used to compute the determinant of a (squared) matrix. In the case of a \\(2 \\times 2\\) matrix, there exists a simple solution for the determinant which is \\[\\begin{equation*} \\text{det} \\left( \\mathbf{D} \\right) = \\text{det} \\left( \\left[ \\begin{matrix} d_1 &amp; d_2\\\\ d_3 &amp; d_4 \\end{matrix} \\right] \\right) = d_1 d_4 - d_2 d_3. \\end{equation*}\\] Consider the matrix \\(\\mathbf{B}\\), we have \\[\\begin{equation*} \\text{det} \\left( \\mathbf{B}\\right) = 30 \\cdot 174 - 70^2 = 320. \\end{equation*}\\] In R, we can simply do det(B) ## [1] 320 The function solve() is also an important function when working with matrices as it allows to inverse a matrix. It is worth remembering that a square matrix that is not invertible (i.e. \\(\\mathbf{A}^{-1}\\) doesn’t exist) is called singular and the determinant offers a way to “check” if this is the case for a given matrix. Indeed, a square matrix is singular if and only if its determinant is 0. Therefore, in the case of \\(\\mathbf{B}\\), we should be able to compute its inverse. As for the determinant, there exists a formula to compute the inverse of \\(2 \\times 2\\) matrices, i.e. \\[\\begin{equation*} \\mathbf{D}^{-1} = \\left[ \\begin{matrix} d_1 &amp; d_2\\\\ d_3 &amp; d_4 \\end{matrix} \\right]^{-1} = \\frac{1}{\\text{det}\\left( \\mathbf{D} \\right)} \\left[ \\begin{matrix} \\phantom{-}d_4 &amp; -d_2\\\\ -d_3 &amp; \\phantom{-}d_1 \\end{matrix} \\right]. \\end{equation*}\\] Considering the matrix \\(\\mathbf{B}\\), we obtain \\[\\begin{equation*} \\mathbf{B}^{-1} = \\left[ \\begin{matrix} 30 &amp; 70\\\\ 70 &amp; 174 \\end{matrix} \\right]^{-1} = \\frac{1}{320}\\left[ \\begin{matrix} \\phantom{-}174 &amp; -70\\\\ -70 &amp; \\phantom{-}30 \\end{matrix} \\right] = \\end{equation*}\\] (B_inv &lt;- solve(B)) ## [,1] [,2] ## [1,] 0.54375 -0.21875 ## [2,] -0.21875 0.09375 Finally, we can verify that \\[\\begin{equation*} \\mathbf{G} = \\mathbf{B} \\mathbf{B}^{-1}, \\end{equation*}\\] should be equal to the identity matrix, (G &lt;- B %*% B_inv) ## [,1] [,2] ## [1,] 1 -8.881784e-16 ## [2,] 0 1.000000e+00 The result is of course extremely close but \\(\\mathbf{G}\\) is not exactly equal to the identity matrix due to rounding and other numerical errors. Another function of interest is the function diag() that can be used to extract the diagonal of a matrix. For example, we have \\[\\begin{equation*} \\text{diag} \\left( \\mathbf{B} \\right) = \\left[30 \\;\\; 174\\right], \\end{equation*}\\] which can be done in R as follows: diag(B) ## [1] 30 174 Therefore, the function diag() allows to easily compute the trace of matrix (i.e. the sum of the diagonal elements). For example, \\[\\begin{equation*} \\text{tr} \\left( \\mathbf{B} \\right) = 204, \\end{equation*}\\] or in R sum(diag(B)) ## [1] 204 Another use of the function diag() is to create diagonal matrices. Indeed, if the argument of this function is a vector, its behavior is the following: \\[\\begin{equation*} \\text{diag} \\left(\\left[a_1 \\;\\; a_2 \\;\\; \\cdots \\;\\; a_n\\right]\\right) = \\left[ \\begin{matrix} a_1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_2 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_n \\end{matrix} \\right]. \\end{equation*}\\] Therefore, this provides a simple way of creating an identity matrix by combining the functions diag() and rep() (discussed in the previous section) as follows: n = 4 (ident &lt;- diag(rep(1, n))) ## [,1] [,2] [,3] [,4] ## [1,] 1 0 0 0 ## [2,] 0 1 0 0 ## [3,] 0 0 1 0 ## [4,] 0 0 0 1 4.2.3 Example: Summary Statistics with Matrix Notation A simple example of the operations we discussed in the previous section is given by many common statistics that can be re-expressed using matrix notation. As an example, we will consider three common statistics that are the sample mean, variance and covariance. Let us consider the following two samples of size \\(n\\) \\[\\begin{equation*} \\begin{aligned} \\mathbf{x} &amp;= \\left[x_1 \\;\\; x_2 \\; \\;\\cdots \\;\\; x_n\\right]^T\\\\ \\mathbf{y} &amp;= \\left[y_1 \\;\\;\\; y_2 \\; \\;\\;\\cdots \\;\\;\\; y_n\\right]^T. \\end{aligned} \\end{equation*}\\] The sample mean of \\(\\mathbf{x}\\) is \\[\\begin{equation*} \\bar{x} = \\frac{1}{n} \\sum_{i = 1}^{n} x_i, \\end{equation*}\\] and its sample variance is \\[\\begin{equation*} s_x^2 = \\frac{1}{n} \\sum_{i = 1}^n \\left(x_i - \\bar{x}\\right)^2. \\end{equation*}\\] The sample covariance between \\(\\mathbf{x}\\) and \\(\\mathbf{y}\\) is \\[\\begin{equation*} s_{x,y} = \\frac{1}{n} \\sum_{i = 1}^n \\left(X_i - \\bar{x}\\right) \\left(Y_i - \\bar{y}\\right), \\end{equation*}\\] where \\(\\bar{y}\\) denotes the sample mean of \\(\\mathbf{y}\\). Consider the sample mean, this statistic can be expressed in matrix notation as follows \\[\\begin{equation*} \\bar{x} = \\frac{1}{n} \\sum_{i = 1}^{n} x_i = \\frac{1}{n} \\mathbf{x}^T \\mathbf{1}, \\end{equation*}\\] where \\(\\mathbf{1}\\) is a column vector of \\(n\\) ones. \\[\\begin{equation*} \\begin{aligned} s_x^2 &amp;= \\frac{1}{n} \\sum_{i = 1}^n \\left(x_i - \\bar{x}\\right)^2 = \\frac{1}{n} \\sum_{i = 1}^n x_i^2 - \\bar{x}^2 = \\frac{1}{n} \\mathbf{x}^T \\mathbf{x} - \\bar{x}^2\\\\ &amp;= \\frac{1}{n} \\mathbf{x}^T \\mathbf{x} - \\left(\\frac{1}{n} \\mathbf{x}^T \\mathbf{1}\\right)^2 = \\frac{1}{n} \\left(\\mathbf{x}^T \\mathbf{x} - \\frac{1}{n} \\mathbf{x}^T \\mathbf{1} \\mathbf{1}^T \\mathbf{x}\\right)\\\\ &amp;= \\frac{1}{n}\\mathbf{x}^T \\left( \\mathbf{I} - \\frac{1}{n} \\mathbf{1} \\mathbf{1}^T \\right) \\mathbf{x} = \\frac{1}{n}\\mathbf{x}^T \\mathbf{H} \\mathbf{x}, \\end{aligned} \\end{equation*}\\] where \\(\\mathbf{H} = \\mathbf{I} - \\frac{1}{n} \\mathbf{1} \\mathbf{1}^T\\). This matrix is often called the centering matrix. Similarly, for the sample covariance we obtain \\[\\begin{equation*} \\begin{aligned} s_{x,y} &amp;= \\frac{1}{n} \\sum_{i = 1}^n \\left(x_i - \\bar{x}\\right) \\left(y_i - \\bar{y}\\right) = \\frac{1}{n}\\mathbf{x}^T \\mathbf{H} \\mathbf{y}. \\end{aligned} \\end{equation*}\\] In the code below we verify the validity of these results through a simple simulated example where we compare the values of the three statistics based on the different formulas discussed above. # Sample size n &lt;- 100 # Simulate random numbers from a zero mean normal distribution with # variance equal to 4. x &lt;- rnorm(n, 0, sqrt(4)) # Simulate random numbers from normal distribution with mean 3 and # variance equal to 1. y &lt;- rnorm(n, 3, 1) # Note that x and y are independent. # Sample mean one &lt;- rep(1, n) x_bar &lt;- 1/n*sum(x) x_bar_mat &lt;- 1/n*t(x)%*%one # Sample variance of x H &lt;- diag(rep(1, n)) - 1/n * one %*% t(one) s_x &lt;- 1/n * sum((x - x_bar)^2) s_x_mat &lt;- 1/n*t(x) %*% H %*% x # Sample covariance y_bar &lt;- 1/n*sum(y) s_xy &lt;- 1/n*sum((x - x_bar)*(y - y_bar)) s_xy_mat &lt;- 1/n*t(x) %*% H %*% y To compare, let’s construct a matrix of all the results that we calculated. cp_matrix = matrix(c(x_bar, x_bar_mat, s_x, s_x_mat, s_xy, s_xy_mat), ncol = 2, byrow = T) row.names(cp_matrix) = c(&quot;Sample Mean&quot;, &quot;Sample Variance&quot;, &quot;Sample Covariance&quot;) colnames(cp_matrix) = c(&quot;Scalar&quot;, &quot;Matrix&quot;) cp_matrix ## Scalar Matrix ## Sample Mean 0.2295960 0.2295960 ## Sample Variance 4.0574283 4.0574283 ## Sample Covariance -0.1406884 -0.1406884 Therefore, using the previously obtained results we can construct the following empirical covariance matrix \\[\\begin{equation} \\widehat{\\text{Cov}}(X, Y) = \\left[ \\begin{matrix} s_x^2 &amp; s_{x,y} \\\\ s_{x,y} &amp; s_y^2 \\end{matrix} \\right]. \\end{equation}\\] In R, this can be done as # Sample variance of y s_y_mat &lt;- 1/n*t(y) %*% H %*% y # Covariance matrix (V &lt;- matrix(c(s_x_mat, s_xy_mat, s_xy_mat, s_y_mat), 2, 2)) ## [,1] [,2] ## [1,] 4.0574283 -0.1406884 ## [2,] -0.1406884 0.8945452 This result can now be compared to cov(cbind(x, y)) ## x y ## x 4.0984124 -0.1421095 ## y -0.1421095 0.9035810 We can see that the results are slightly different from what we expected. This is because the calculation of cov() within the default R stats package is based on an unbiased estimator which is not the one we used. To obtain the exact same result, we can go back to our estimation by calculating via the below method (n-1)/n*cov(cbind(x, y)) ## x y ## x 4.0574283 -0.1406884 ## y -0.1406884 0.8945452 4.2.4 Example: Portfolio Optimzation Suppose that you are interested in investing your money in two stocks, say Apple and Amazon. However, you are wondering how much of each stock you should buy. To make it simple let us assume that you will invest \\(\\omega W\\) in Apple (AAPL) and \\((1-\\omega) W\\) in Netflix (NFLX), where \\(X\\) denotes the amount of money you would like to invest and \\(\\omega\\) is such that \\(\\omega \\in [0, \\, 1]\\). Let \\(R_A\\) and \\(R_N\\) denote, respectively, the daily return (see Equation (4.1) if you don’t remeber what returns are) of Apple and Netflix. To make things simple we assume that the returns \\(R_A\\) and \\(R_N\\) are jointly normally distributed so we can write \\[ \\mathbf{R} \\stackrel{iid}{\\sim} \\mathcal{N} \\left(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}\\right) \\] where \\[ \\mathbf{R} = \\left[ \\begin{matrix} R_A\\\\ R_N \\end{matrix} \\right], \\;\\;\\;\\; \\boldsymbol{\\mu} = \\left[ \\begin{matrix} \\mu_A\\\\ \\mu_N \\end{matrix} \\right], \\;\\; \\text{and}\\;\\; \\boldsymbol{\\Sigma} = \\left[ \\begin{matrix} \\sigma_A^2 &amp; \\sigma_{AN}\\\\ \\sigma_{AN} &amp; \\sigma_N^2 \\end{matrix} \\right]. \\] Using these assumptions, the classical portfolio optimzation problem, which would allow you to determine a “good” value of \\(\\omega\\), can stated as follows. Given our initial wealth \\(X\\), the investement problem is to decide how much should be invested in our first asset (Apple) and in our second asset (Netflix). As mention earlier we assume that \\(\\omega \\in [0,\\,1]\\), implying that it is only possible to buy the two assets (i.e. short positions are not allowed). Therefore, to solve our investement problem we must choose the value of \\(\\omega\\) which would maximize your personal utility. Informally speaking the utility represent a measurement of the “useful-ness” that a is obtained from your investement. To consider a simple case, we will assume that you are a particularly risk adverse individual (i.e. you are looking for an investement that is as sure as possible) and as such you want to pick the value of \\(\\omega\\) providing you with the smallest investement risk. We can then the optimal value of \\(\\omega\\) as follows. First, we construct a new random variable, say \\(Y\\), which denotes the return of your portfolio. Since you invest \\(\\omega W\\) in Apple and \\((1 - \\omega) W\\) in Netflix, it is easy to see that \\[Y = \\left[\\omega R_A + (1 - \\omega) R_N \\right]W.\\] In general the risk and variance of an investement are two different things but in our case we assumed that \\(\\mathbf{R}\\) is normally distributed and in such the variance perfectely characterize the risk of your investement. Therefore, we can define the risk of our investement as the following function of \\(\\omega\\) \\[f(\\omega) = \\text{Risk}(Y) = \\text{Var} (Y) = \\left[\\omega^2 \\sigma_A^2 + (1 - \\omega)^2 \\sigma_N^2 + 2 \\omega (1 - \\omega) \\sigma_{AN}\\right]W^2.\\] The function \\(f(\\omega)\\) is minimized for the value \\(\\omega^*\\) which is given by \\[\\begin{equation} \\omega^* = \\frac{\\sigma^2_N - \\sigma_{AN}}{\\sigma^2_A + \\sigma^2_N - 2\\sigma_{AN}}. \\tag{4.2} \\end{equation}\\] If you interested in understanding how Equation (4.2) was obtain click on the button below:  Minimum Variance Portfolio Derivation To obtain \\(\\omega^*\\) we first differentiate the function \\(f(\\omega)\\) with respect to \\(\\omega\\), which gives \\[\\begin{equation} \\frac{\\partial}{\\partial \\omega} \\, f(\\omega) = \\left[2 \\omega \\sigma_A^2 - 2 (1 - \\omega) \\sigma_N^2 + 2 (1 - 2\\omega) \\sigma_{AN}\\right]W^2 \\end{equation}\\] Then, we define \\(\\omega^*\\) as \\[\\begin{equation} \\omega^* \\; : \\frac{\\partial}{\\partial \\omega} \\, f(\\omega) = 0. \\end{equation}\\] Therefore, we obtain \\[\\begin{equation} \\omega^* \\left(\\sigma_A^2 + \\sigma_N^2 - 2 \\sigma_{AN}\\right) = \\sigma_N^2 - \\sigma_{AN}, \\end{equation}\\] which simplifies to \\[\\begin{equation} \\omega^* = \\frac{\\sigma_N^2 - \\sigma_{AN}}{\\sigma_A^2 + \\sigma_N^2 - 2 \\sigma_{AN}}. \\end{equation}\\] Finally, we verify that our result is a minimum by considering the second derivative, i.e. \\[\\begin{equation} \\frac{\\partial^2}{\\partial \\omega^2} \\, f(\\omega) = 2W\\left[\\sigma_A^2 + \\sigma_N^2 - 2\\sigma_{AN} \\sigma_{AN}\\right]. \\end{equation}\\] Since \\(W\\) is strictely positive all that remains to conclude our derivation is veryfying that \\(\\sigma_A^2 + \\sigma_N^2 - 2\\sigma_{AN} \\sigma_{AN} \\leq 0\\). In fact, this is a well known inequality which is a direct consequence of Tchebychev inequality. However, here is a simpler argument to understand why this is the case. Indeed, it is obvious that \\(\\text{Var}(R_A - R_N) \\leq 0\\) and we also have \\(\\text{Var}(R_A - R_N) = \\sigma_A^2 + \\sigma_N^2 - 2\\sigma_{AN}\\). Thus, we obtain \\[\\text{Var}(R_A - R_N) = \\sigma_A^2 + \\sigma_N^2 - 2\\sigma_{AN} \\leq 0,\\] which verifies that our result is a minimum. Using (4.2), we obtain that the expected value and variance of our investement are given by \\[ \\begin{aligned} \\text{Expected Value Investement} &amp;=\\left[\\omega^* \\mu_A + (1 - \\omega^*) \\mu_N\\right] W,\\\\ \\text{Variance Investement} &amp;= \\left[(\\omega^*)^2 \\sigma_A^2 + (1 - \\omega^*)^2 \\sigma_N^2 + 2 \\omega^* (1 - \\omega^*) \\sigma_{AN}\\right]W^2. \\end{aligned} \\] In practice, the vector \\(\\boldsymbol{\\mu}\\) and matrix \\(\\boldsymbol{\\Sigma}\\) are unknown and must be estimated on historical data. In the code below, we compute the optimal value of \\(\\omega\\) based on (4.2) using the last five years of historical data for the two stocks considered. # Load quantmod library(quantmod) # Download data today &lt;- Sys.Date() five_years_ago &lt;- seq(today, length = 2, by = &quot;-5 year&quot;)[2] getSymbols(&quot;AAPL&quot;, from = five_years_ago, to = today) getSymbols(&quot;NFLX&quot;, from = five_years_ago, to = today) # Compute returns Ra &lt;- na.omit(ClCl(AAPL)) Rn &lt;- na.omit(ClCl(NFLX)) # Estimation of mu and Sigma Sigma &lt;- cov(cbind(Ra, Rn)) mu &lt;- c(mean(Ra), mean(Rn)) # Compute omega^* omega_star = (Sigma[2, 2] - Sigma[1, 2])/(Sigma[1, 1] + Sigma[2, 2] - 2*Sigma[1, 2]) # Compute investement expected value and variance mu_investement = omega_star*mu[1] + (1 - omega_star)*mu[2] var_investement = omega_star^2*Sigma[1,1] + (1 - omega_star)^2*Sigma[2,2] + 2*omega_star*(1 - omega_star)*Sigma[1,2] From this code, we obtain \\(\\omega^* \\approx\\) 82.33%. In the table below we compare the empirical expected values and variances of the stocks stocks as well as those of our investement: investement_summary = matrix(NA, 2, 3) dimnames(investement_summary)[[1]] = c(&quot;Expected value&quot;, &quot;Variance&quot;) dimnames(investement_summary)[[2]] = c(&quot;Apple&quot;, &quot;Netflix&quot;, &quot;Investement&quot;) investement_summary[1, ] = c(mu, mu_investement) investement_summary[2, ] = c(diag(Sigma), var_investement) knitr::kable(investement_summary, caption = &quot;TO DO&quot;) Table 4.4: TO DO Apple Netflix Investement Expected value 0.0005302 0.0029468 0.0009572 Variance 0.0002469 0.0010042 0.0002103 In Table 4.4 we can observe that our … plot(sqrt(c(diag(Sigma), var_investement)), c(mu, mu_investement)) Placeholder "]
]
